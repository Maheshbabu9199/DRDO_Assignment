{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Questions 05\n",
        "\n",
        "A military organization wants to develop a machine learning model that can identify enemy\n",
        "vehicles in satellite imagery. The model will take as input a satellite image and output a list\n",
        "of bounding boxes that correspond to the location of enemy vehicles in the image. Develop\n",
        "a ML solution for the aforesaid scenario with an example Dataset."
      ],
      "metadata": {
        "id": "Ii01mYNnnpvM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implemeting the necessary libraries"
      ],
      "metadata": {
        "id": "bg_zTPWVnY_3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3nSU375tO-ZO"
      },
      "outputs": [],
      "source": [
        "# For data manipulation\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# For saving the model\n",
        "import pickle\n",
        "\n",
        "# For warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "# importing the pre-trained YOLO model class\n",
        "from ultralytics import YOLO\n",
        "import yaml\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Here in this cell, we have taken the pre-trained yolov8 model.\n",
        "\n",
        "There are many versions of YOLO models available but the factors that make the difference in each and every version is the speed,accuracy and parameters and mAP (mean average precision value)."
      ],
      "metadata": {
        "id": "Vy3ppgFVbbvM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# About the dataset\n",
        "\n",
        "\n",
        "Dataset Structure\n",
        "Open Images V7 is structured in multiple components catering to varied computer vision challenges:\n",
        "\n",
        "Images: About 9 million images, often showcasing intricate scenes with an average of 8.3 objects per image.\n",
        "Bounding Boxes: Over 16 million boxes that demarcate objects across 600 categories.\n",
        "Segmentation Masks: These detail the exact boundary of 2.8M objects across 350 classes.\n",
        "Visual Relationships: 3.3M annotations indicating object relationships, properties, and actions.\n",
        "Localized Narratives: 675k descriptions combining voice, text, and mouse traces.\n",
        "Point-Level Labels: 66.4M labels across 1.4M images, suitable for zero/few-shot semantic segmentation."
      ],
      "metadata": {
        "id": "HWN2Knq6lpzl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the pre-trained model\n",
        "\n",
        "base_model = YOLO(\"yolov8n.pt\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ao4UPk-OT3X3",
        "outputId": "cc43fa75-b2fa-4484-bbc6-cef844f9d293"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt to 'yolov8n.pt'...\n",
            "100%|██████████| 6.23M/6.23M [00:00<00:00, 22.6MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the pre-trained model with the custom dataset and create a new model\n",
        "base_model.train(epochs=100)"
      ],
      "metadata": {
        "id": "YvyJGUwub-0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.predict(\"/content/erik-mclean-ZRns2R5azu0-unsplash.jpg\", save=True, classes=[2,3,5,7])"
      ],
      "metadata": {
        "id": "97EloUIGVu58"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# In the above concept, we have used the YOLO algorithms\n",
        "\n",
        "YOLO (You look only Once) algorithm looks at the images only once and will be able to predict the objects inside the images.\n",
        "\n",
        "This works on the concept of taking the images and forming the bounding rectangle boxes vertically and horizontally.\n",
        "\n",
        "Once the images are formed this will take the most common area of the two bounding boxes as moving from left to right.\n",
        "The algorithm used to filter the bounding boxes based on their weightage is non-maximum suppression(NMS).\n",
        "\n",
        "This is used for sorting out the algorithms with more weightage and remove the remaining both in rectangle and horizontal boxes.\n",
        "\n",
        "Once the area is figured out, it then classifies whether the area belongs to which class.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FE3R1OQRbbpn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# About the integration of this model with the application for the military scenario\n",
        "\n",
        "This model can be used with the application for the detecting the images of the vehicles (car,truck,bike).\n",
        "\n",
        "We can build an application using the front-end technologies and integrate using flask, Django.\n",
        "\n",
        "We can take the input of the image from the user, process it directly to the model.predict and return the result to the user.\n",
        "\n",
        "We can use the functionality of the flask or Django along with Python for this implementation.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "S8Nrovpzl9Nf"
      }
    }
  ]
}